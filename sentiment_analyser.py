# -*- coding: utf-8 -*-
"""Sentiment_Analyser

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18_kG_LdtYgcME82Op-MXvIO7p7sz5PGN
"""

import nltk
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.pipeline import Pipeline
from textblob import TextBlob
import re
import seaborn as sns
import matplotlib.pyplot as plt

# Download required NLTK data
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('vader_lexicon', quiet=True)

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.sentiment import SentimentIntensityAnalyzer

class SentimentAnalyzer:
    def __init__(self):
        self.stop_words = set(stopwords.words('english'))
        self.lemmatizer = WordNetLemmatizer()
        self.vader_analyzer = SentimentIntensityAnalyzer()
        self.models = {}
        self.vectorizer = None

    def create_sample_dataset(self):
        """Create a sample dataset with 100 sentences"""
        data = [
            # Positive sentences (33)
            ("I love this movie, it's absolutely fantastic!", "positive"),
            ("This is the best day of my life!", "positive"),
            ("Amazing service and delicious food!", "positive"),
            ("I'm so happy with my purchase!", "positive"),
            ("Excellent quality and fast delivery!", "positive"),
            ("This product exceeded my expectations!", "positive"),
            ("Beautiful weather today, perfect for a walk!", "positive"),
            ("I feel great after that workout!", "positive"),
            ("Wonderful experience, highly recommend!", "positive"),
            ("The staff was incredibly helpful and friendly!", "positive"),
            ("This book is a masterpiece!", "positive"),
            ("I'm thrilled with the results!", "positive"),
            ("Outstanding performance by the team!", "positive"),
            ("Love the new design, very intuitive!", "positive"),
            ("Perfect timing, exactly what I needed!", "positive"),
            ("Brilliant solution to a complex problem!", "positive"),
            ("I'm impressed by the attention to detail!", "positive"),
            ("Fantastic customer support!", "positive"),
            ("This is exactly what I was looking for!", "positive"),
            ("Incredible value for money!", "positive"),
            ("The presentation was inspiring and motivating!", "positive"),
            ("Great job on the project!", "positive"),
            ("I enjoyed every minute of it!", "positive"),
            ("Superb quality and craftsmanship!", "positive"),
            ("This made my day so much better!", "positive"),
            ("Awesome features and easy to use!", "positive"),
            ("I'm completely satisfied with this service!", "positive"),
            ("Beautiful scenery and peaceful atmosphere!", "positive"),
            ("The team delivered exceptional results!", "positive"),
            ("This is a game-changer!", "positive"),
            ("Perfect fit and comfortable!", "positive"),
            ("I'm grateful for this opportunity!", "positive"),
            ("Remarkable improvement in performance!", "positive"),

            # Negative sentences (33)
            ("This is the worst product I've ever bought!", "negative"),
            ("Terrible service, very disappointed!", "negative"),
            ("I hate waiting in long lines!", "negative"),
            ("The food was cold and tasteless!", "negative"),
            ("Poor quality, not worth the money!", "negative"),
            ("I regret making this purchase!", "negative"),
            ("Awful experience, would not recommend!", "negative"),
            ("The customer service was rude and unhelpful!", "negative"),
            ("This software is full of bugs!", "negative"),
            ("Horrible weather ruined our plans!", "negative"),
            ("I'm frustrated with the constant delays!", "negative"),
            ("The movie was boring and predictable!", "negative"),
            ("Disgusting smell and dirty environment!", "negative"),
            ("I'm extremely dissatisfied with the results!", "negative"),
            ("Pathetic performance by the team!", "negative"),
            ("The design is confusing and user-unfriendly!", "negative"),
            ("Waste of time and money!", "negative"),
            ("I'm angry about the false advertising!", "negative"),
            ("Terrible quality control issues!", "negative"),
            ("The delivery was delayed and damaged!", "negative"),
            ("Uncomfortable seating and poor acoustics!", "negative"),
            ("I'm disappointed with the lack of features!", "negative"),
            ("Unacceptable behavior from the staff!", "negative"),
            ("This is a complete disaster!", "negative"),
            ("Poor communication and missed deadlines!", "negative"),
            ("The interface is slow and unresponsive!", "negative"),
            ("I feel cheated by this company!", "negative"),
            ("Annoying ads and constant interruptions!", "negative"),
            ("The product broke after one week!", "negative"),
            ("Unprofessional service and attitude!", "negative"),
            ("I'm tired of these technical problems!", "negative"),
            ("Overpriced and underdelivered!", "negative"),
            ("This is completely useless!", "negative"),

            # Neutral sentences (34)
            ("The meeting is scheduled for 3 PM tomorrow.", "neutral"),
            ("I need to buy groceries after work.", "neutral"),
            ("The report contains statistical data from last quarter.", "neutral"),
            ("Please submit your application by Friday.", "neutral"),
            ("The temperature today is 72 degrees Fahrenheit.", "neutral"),
            ("This document has five pages.", "neutral"),
            ("The store opens at 9 AM on weekdays.", "neutral"),
            ("I will attend the conference next week.", "neutral"),
            ("The project deadline is approaching.", "neutral"),
            ("There are three options available.", "neutral"),
            ("The train arrives at platform 2.", "neutral"),
            ("I received your email this morning.", "neutral"),
            ("The library is located on Main Street.", "neutral"),
            ("We need to update the software version.", "neutral"),
            ("The presentation slides are ready for review.", "neutral"),
            ("I work in the marketing department.", "neutral"),
            ("The conference room is booked until 4 PM.", "neutral"),
            ("Please find the attached file.", "neutral"),
            ("The product specifications are listed below.", "neutral"),
            ("I'll be traveling to New York next month.", "neutral"),
            ("The system maintenance is scheduled for tonight.", "neutral"),
            ("There are 50 participants in the study.", "neutral"),
            ("The invoice was sent last Tuesday.", "neutral"),
            ("I'm currently reviewing the contract terms.", "neutral"),
            ("The new policy takes effect next quarter.", "neutral"),
            ("Please confirm your attendance by email.", "neutral"),
            ("The data shows a 5% increase.", "neutral"),
            ("I have a dentist appointment at 2 PM.", "neutral"),
            ("The file size is 2.5 MB.", "neutral"),
            ("We offer three payment methods.", "neutral"),
            ("The office is closed on public holidays.", "neutral"),
            ("I need to renew my subscription.", "neutral"),
            ("The manual is available in PDF format.", "neutral"),
            ("The meeting room capacity is 20 people.", "neutral")
        ]

        return pd.DataFrame(data, columns=['text', 'sentiment'])

    def preprocess_text(self, text):
        """Preprocess text data"""
        # Convert to lowercase
        text = text.lower()

        # Remove special characters and digits
        text = re.sub(r'[^a-zA-Z\s]', '', text)

        # Tokenize
        tokens = word_tokenize(text)

        # Remove stopwords and lemmatize
        tokens = [self.lemmatizer.lemmatize(token) for token in tokens
                 if token not in self.stop_words and len(token) > 2]

        return ' '.join(tokens)

    def train_models(self, X_train, y_train):
        """Train multiple models"""
        # TF-IDF Vectorizer
        self.vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))
        X_train_vec = self.vectorizer.fit_transform(X_train)

        # Models to train
        models = {
            'Naive Bayes': MultinomialNB(),
            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
            'SVM': SVC(kernel='linear', random_state=42)
        }

        # Train each model
        for name, model in models.items():
            model.fit(X_train_vec, y_train)
            self.models[name] = model

        return X_train_vec

    def evaluate_models(self, X_test, y_test):
        """Evaluate all trained models"""
        X_test_vec = self.vectorizer.transform(X_test)
        results = {}

        for name, model in self.models.items():
            y_pred = model.predict(X_test_vec)
            accuracy = accuracy_score(y_test, y_pred)
            results[name] = {
                'accuracy': accuracy,
                'predictions': y_pred,
                'classification_report': classification_report(y_test, y_pred)
            }

        return results

    def textblob_sentiment(self, texts):
        """Get sentiment using TextBlob"""
        sentiments = []
        for text in texts:
            blob = TextBlob(text)
            polarity = blob.sentiment.polarity
            if polarity > 0.1:
                sentiments.append('positive')
            elif polarity < -0.1:
                sentiments.append('negative')
            else:
                sentiments.append('neutral')
        return sentiments

    def vader_sentiment(self, texts):
        """Get sentiment using VADER"""
        sentiments = []
        for text in texts:
            scores = self.vader_analyzer.polarity_scores(text)
            compound = scores['compound']
            if compound >= 0.05:
                sentiments.append('positive')
            elif compound <= -0.05:
                sentiments.append('negative')
            else:
                sentiments.append('neutral')
        return sentiments

    def plot_confusion_matrix(self, y_true, y_pred, model_name):
        """Plot confusion matrix"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=['negative', 'neutral', 'positive'],
                   yticklabels=['negative', 'neutral', 'positive'])
        plt.title(f'Confusion Matrix - {model_name}')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.tight_layout()
        plt.show()

def main():
    # Initialize the analyzer
    analyzer = SentimentAnalyzer()

    # Create dataset
    print("Creating sample dataset...")
    df = analyzer.create_sample_dataset()
    print(f"Dataset created with {len(df)} samples")
    print(f"Sentiment distribution:\n{df['sentiment'].value_counts()}\n")

    # Preprocess text
    print("Preprocessing text...")
    df['processed_text'] = df['text'].apply(analyzer.preprocess_text)

    # Split data
    X = df['processed_text']
    y = df['sentiment']
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    print(f"Training set size: {len(X_train)}")
    print(f"Test set size: {len(X_test)}\n")

    # Train models
    print("Training machine learning models...")
    analyzer.train_models(X_train, y_train)

    # Evaluate models
    print("Evaluating models...")
    results = analyzer.evaluate_models(X_test, y_test)

    # Display results
    print("=== MODEL PERFORMANCE COMPARISON ===\n")

    for model_name, result in results.items():
        print(f"{model_name}:")
        print(f"Accuracy: {result['accuracy']:.4f}")
        print(f"Classification Report:\n{result['classification_report']}")
        print("-" * 50)

    # Test with rule-based approaches
    print("\n=== RULE-BASED APPROACHES ===\n")

    # TextBlob
    textblob_pred = analyzer.textblob_sentiment(X_test.tolist())
    textblob_accuracy = accuracy_score(y_test, textblob_pred)
    print(f"TextBlob Accuracy: {textblob_accuracy:.4f}")

    # VADER
    vader_pred = analyzer.vader_sentiment(X_test.tolist())
    vader_accuracy = accuracy_score(y_test, vader_pred)
    print(f"VADER Accuracy: {vader_accuracy:.4f}")

    # Find best model
    best_model = max(results.keys(), key=lambda x: results[x]['accuracy'])
    best_accuracy = results[best_model]['accuracy']

    print(f"\n=== BEST PERFORMING MODEL ===")
    print(f"Model: {best_model}")
    print(f"Accuracy: {best_accuracy:.4f}")

    # Plot confusion matrix for best model
    analyzer.plot_confusion_matrix(y_test, results[best_model]['predictions'], best_model)

    # Test with new examples
    print("\n=== TESTING WITH NEW EXAMPLES ===")

    test_sentences = [
        "I absolutely love this new feature!",
        "This is terrible, I want my money back.",
        "The system will be updated tomorrow.",
        "Outstanding work by the development team!",
        "The application crashed again, very frustrating."
    ]

    # Preprocess test sentences
    processed_test = [analyzer.preprocess_text(sent) for sent in test_sentences]
    test_vec = analyzer.vectorizer.transform(processed_test)

    # Predict with best model
    best_model_obj = analyzer.models[best_model]
    predictions = best_model_obj.predict(test_vec)

    print(f"Predictions using {best_model}:")
    for i, (sentence, pred) in enumerate(zip(test_sentences, predictions)):
        print(f"{i+1}. '{sentence}' -> {pred}")

    # Performance analysis
    print("\n=== PERFORMANCE ANALYSIS ===")

    all_accuracies = {**{name: results[name]['accuracy'] for name in results},
                     'TextBlob': textblob_accuracy, 'VADER': vader_accuracy}

    sorted_models = sorted(all_accuracies.items(), key=lambda x: x[1], reverse=True)

    print("Model Ranking by Accuracy:")
    for i, (model, acc) in enumerate(sorted_models, 1):
        print(f"{i}. {model}: {acc:.4f}")

    return analyzer, results



if __name__ == "__main__":
    # Run the main analysis
    analyzer, results = main()